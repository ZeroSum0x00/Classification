Model: "BEiT-Base-16"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 224, 224, 3)]     0         
                                                                 
 stem_conv (PatchConv2DWith  (None, 14, 14, 768)       590592    
 ResampleWeights)                                                
                                                                 
 reshape (Reshape)           (None, 196, 768)          0         
                                                                 
 cls_token (ClassToken)      (None, 197, 768)          768       
                                                                 
 AttentionMLP_block_1 (Atte  (None, 197, 768)          7097424   
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_2 (Atte  (None, 197, 768)          7097424   
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_3 (Atte  (None, 197, 768)          7097424   
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_4 (Atte  (None, 197, 768)          7097424   
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_5 (Atte  (None, 197, 768)          7097424   
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_6 (Atte  (None, 197, 768)          7097424   
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_7 (Atte  (None, 197, 768)          7097424   
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_8 (Atte  (None, 197, 768)          7097424   
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_9 (Atte  (None, 197, 768)          7097424   
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_10 (Att  (None, 197, 768)          7097424   
 entionMLPBlock)                                                 
                                                                 
 AttentionMLP_block_11 (Att  (None, 197, 768)          7097424   
 entionMLPBlock)                                                 
                                                                 
 AttentionMLP_block_12 (Att  (None, 197, 768)          7097424   
 entionMLPBlock)                                                 
                                                                 
 tf.__operators__.getitem (  (None, 196, 768)          0         
 SlicingOpLambda)                                                
                                                                 
 tf.math.reduce_mean (TFOpL  (None, 768)               0         
 ambda)                                                          
                                                                 
 out_ln (LayerNormalization  (None, 768)               1536      
 )                                                               
                                                                 
 predictions (Dense)         (None, 1000)              769000    
                                                                 
 activation_8 (Activation)   (None, 1000)              0         
                                                                 
=================================================================
Total params: 86530984 (330.09 MB)
Trainable params: 86530984 (330.09 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
