Model: "Meta-Transformer-Large-14"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_20 (InputLayer)       [(None, 224, 224, 3)]     0         
                                                                 
 stem_conv (PatchConv2DWith  (None, 16, 16, 1024)      602112    
 ResampleWeights)                                                
                                                                 
 reshape_1 (Reshape)         (None, 256, 1024)         0         
                                                                 
 cls_token (ClassToken)      (None, 257, 1024)         1024      
                                                                 
 positional_embedding (Posi  (None, 257, 1024)         263168    
 tionalEmbedding)                                                
                                                                 
 pre_ln (LayerNormalization  (None, 257, 1024)         2048      
 )                                                               
                                                                 
 AttentionMLP_block_1 (Atte  (None, 257, 1024)         12596224  
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_2 (Atte  (None, 257, 1024)         12596224  
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_3 (Atte  (None, 257, 1024)         12596224  
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_4 (Atte  (None, 257, 1024)         12596224  
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_5 (Atte  (None, 257, 1024)         12596224  
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_6 (Atte  (None, 257, 1024)         12596224  
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_7 (Atte  (None, 257, 1024)         12596224  
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_8 (Atte  (None, 257, 1024)         12596224  
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_9 (Atte  (None, 257, 1024)         12596224  
 ntionMLPBlock)                                                  
                                                                 
 AttentionMLP_block_10 (Att  (None, 257, 1024)         12596224  
 entionMLPBlock)                                                 
                                                                 
 AttentionMLP_block_11 (Att  (None, 257, 1024)         12596224  
 entionMLPBlock)                                                 
                                                                 
 AttentionMLP_block_12 (Att  (None, 257, 1024)         12596224  
 entionMLPBlock)                                                 
                                                                 
 AttentionMLP_block_13 (Att  (None, 257, 1024)         12596224  
 entionMLPBlock)                                                 
                                                                 
 AttentionMLP_block_14 (Att  (None, 257, 1024)         12596224  
 entionMLPBlock)                                                 
                                                                 
 AttentionMLP_block_15 (Att  (None, 257, 1024)         12596224  
 entionMLPBlock)                                                 
                                                                 
 AttentionMLP_block_16 (Att  (None, 257, 1024)         12596224  
 entionMLPBlock)                                                 
                                                                 
 AttentionMLP_block_17 (Att  (None, 257, 1024)         12596224  
 entionMLPBlock)                                                 
                                                                 
 AttentionMLP_block_18 (Att  (None, 257, 1024)         12596224  
 entionMLPBlock)                                                 
                                                                 
 AttentionMLP_block_19 (Att  (None, 257, 1024)         12596224  
 entionMLPBlock)                                                 
                                                                 
 AttentionMLP_block_20 (Att  (None, 257, 1024)         12596224  
 entionMLPBlock)                                                 
                                                                 
 AttentionMLP_block_21 (Att  (None, 257, 1024)         12596224  
 entionMLPBlock)                                                 
                                                                 
 AttentionMLP_block_22 (Att  (None, 257, 1024)         12596224  
 entionMLPBlock)                                                 
                                                                 
 AttentionMLP_block_23 (Att  (None, 257, 1024)         12596224  
 entionMLPBlock)                                                 
                                                                 
 AttentionMLP_block_24 (Att  (None, 257, 1024)         12596224  
 entionMLPBlock)                                                 
                                                                 
 out_ln (LayerNormalization  (None, 257, 1024)         2048      
 )                                                               
                                                                 
 tf.__operators__.getitem_1  (None, 1024)              0         
  (SlicingOpLambda)                                              
                                                                 
 predictions (Dense)         (None, 1000)              1025000   
                                                                 
 activation_40 (Activation)  (None, 1000)              0         
                                                                 
=================================================================
Total params: 304204776 (1.13 GB)
Trainable params: 304204776 (1.13 GB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
